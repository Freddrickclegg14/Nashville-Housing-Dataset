import numpy as np 
import pandas as pd 
from pandas import DataFrame, Series 
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline
import warnings
warnings.filterwarnings("ignore")
df = pd.read_excel(r'C:\Users\Mrs L.O LLadipo-Cleg\Documents\Data Analyst Personal Work\Data Science Work\Jupyter Lesson\Nashville Housing Data for Data Cleaning.xlsx')
df.head(5)
UniqueID	ParcelID	LandUse	PropertyAddress	SaleDate	SalePrice	LegalReference	SoldAsVacant	OwnerName	OwnerAddress	Acreage	TaxDistrict	LandValue	BuildingValue	TotalValue	YearBuilt	Bedrooms	FullBath	HalfBath
0	2045	007 00 0 125.00	SINGLE FAMILY	1808 FOX CHASE DR, GOODLETTSVILLE	2013-04-09	240000	20130412-0036474	No	FRAZIER, CYRENTHA LYNETTE	1808 FOX CHASE DR, GOODLETTSVILLE, TN	2.3	GENERAL SERVICES DISTRICT	50000.0	168200.0	235700.0	1986.0	3.0	3.0	0.0
1	16918	007 00 0 130.00	SINGLE FAMILY	1832 FOX CHASE DR, GOODLETTSVILLE	2014-06-10	366000	20140619-0053768	No	BONER, CHARLES & LESLIE	1832 FOX CHASE DR, GOODLETTSVILLE, TN	3.5	GENERAL SERVICES DISTRICT	50000.0	264100.0	319000.0	1998.0	3.0	3.0	2.0
2	54582	007 00 0 138.00	SINGLE FAMILY	1864 FOX CHASE DR, GOODLETTSVILLE	2016-09-26	435000	20160927-0101718	No	WILSON, JAMES E. & JOANNE	1864 FOX CHASE DR, GOODLETTSVILLE, TN	2.9	GENERAL SERVICES DISTRICT	50000.0	216200.0	298000.0	1987.0	4.0	3.0	0.0
3	43070	007 00 0 143.00	SINGLE FAMILY	1853 FOX CHASE DR, GOODLETTSVILLE	2016-01-29	255000	20160129-0008913	No	BAKER, JAY K. & SUSAN E.	1853 FOX CHASE DR, GOODLETTSVILLE, TN	2.6	GENERAL SERVICES DISTRICT	50000.0	147300.0	197300.0	1985.0	3.0	3.0	0.0
4	22714	007 00 0 149.00	SINGLE FAMILY	1829 FOX CHASE DR, GOODLETTSVILLE	2014-10-10	278000	20141015-0095255	No	POST, CHRISTOPHER M. & SAMANTHA C.	1829 FOX CHASE DR, GOODLETTSVILLE, TN	2.0	GENERAL SERVICES DISTRICT	50000.0	152300.0	202300.0	1984.0	4.0	3.0	0.0
row, col = df.shape
print("This Dataset has",row,"rows and",col, "columns")
This Dataset has 56477 rows and 19 columns
dups = df.duplicated().sum()
print("This Dataset has",dups,"duplicates")
This Dataset has 0 duplicates
df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 56477 entries, 0 to 56476
Data columns (total 19 columns):
 #   Column           Non-Null Count  Dtype         
---  ------           --------------  -----         
 0   UniqueID         56477 non-null  int64         
 1   ParcelID         56477 non-null  object        
 2   LandUse          56477 non-null  object        
 3   PropertyAddress  56448 non-null  object        
 4   SaleDate         56477 non-null  datetime64[ns]
 5   SalePrice        56477 non-null  int64         
 6   LegalReference   56477 non-null  object        
 7   SoldAsVacant     56477 non-null  object        
 8   OwnerName        25261 non-null  object        
 9   OwnerAddress     26015 non-null  object        
 10  Acreage          26015 non-null  float64       
 11  TaxDistrict      26015 non-null  object        
 12  LandValue        26015 non-null  float64       
 13  BuildingValue    26015 non-null  float64       
 14  TotalValue       26015 non-null  float64       
 15  YearBuilt        24163 non-null  float64       
 16  Bedrooms         24157 non-null  float64       
 17  FullBath         24275 non-null  float64       
 18  HalfBath         24144 non-null  float64       
dtypes: datetime64[ns](1), float64(8), int64(2), object(8)
memory usage: 8.2+ MB
df.describe()
UniqueID	SaleDate	SalePrice	Acreage	LandValue	BuildingValue	TotalValue	YearBuilt	Bedrooms	FullBath	HalfBath
count	56477.000000	56477	5.647700e+04	26015.000000	2.601500e+04	2.601500e+04	2.601500e+04	24163.000000	24157.000000	24275.000000	24144.000000
mean	28334.001133	2015-02-08 08:02:27.373267200	3.272264e+05	0.498923	6.906856e+04	1.607847e+05	2.323754e+05	1963.744899	3.089912	1.886014	0.283921
min	0.000000	2013-01-02 00:00:00	5.000000e+01	0.010000	1.000000e+02	0.000000e+00	1.000000e+02	1799.000000	0.000000	0.000000	0.000000
25%	14186.000000	2014-04-11 00:00:00	1.350000e+05	0.180000	2.100000e+04	7.590000e+04	1.028000e+05	1948.000000	3.000000	1.000000	0.000000
50%	28313.000000	2015-03-24 00:00:00	2.051000e+05	0.270000	2.880000e+04	1.114000e+05	1.485000e+05	1960.000000	3.000000	2.000000	0.000000
75%	42513.000000	2015-12-30 00:00:00	3.285000e+05	0.450000	6.000000e+04	1.807000e+05	2.683500e+05	1983.000000	3.000000	2.000000	1.000000
max	56635.000000	2019-12-13 00:00:00	5.427806e+07	160.060000	2.772000e+06	1.297180e+07	1.394040e+07	2017.000000	11.000000	10.000000	3.000000
std	16352.590651	NaN	9.298326e+05	1.570454	1.060401e+05	2.067999e+05	2.810643e+05	26.542982	0.852869	0.961515	0.487881
pd.set_option('display.float_format', lambda x: '%.2f' % x)
df.columns
Index(['UniqueID ', 'ParcelID', 'LandUse', 'PropertyAddress', 'SaleDate',
       'SalePrice', 'LegalReference', 'SoldAsVacant', 'OwnerName',
       'OwnerAddress', 'Acreage', 'TaxDistrict', 'LandValue', 'BuildingValue',
       'TotalValue', 'YearBuilt', 'Bedrooms', 'FullBath', 'HalfBath'],
      dtype='object')
df = df.rename(columns={
    'SalePrice': 'Sale_Price($)',
    'LandValue': 'Land_Value($)',
    'BuildingValue': 'Building_Value($)',
    'TotalValue': 'Total_Value($)',
})
df = df[['UniqueID ', 'ParcelID', 'PropertyAddress', 'OwnerAddress','LandUse', 'OwnerName',
    'LegalReference','Acreage', 'TaxDistrict','Bedrooms', 'FullBath', 'HalfBath', 
    'Land_Value($)', 'Building_Value($)','Total_Value($)', 'Sale_Price($)', 'SaleDate','SoldAsVacant','YearBuilt' ]]
df.isna().sum()
UniqueID                 0
ParcelID                 0
PropertyAddress         29
OwnerAddress         30462
LandUse                  0
OwnerName            31216
LegalReference           0
Acreage              30462
TaxDistrict          30462
Bedrooms             32320
FullBath             32202
HalfBath             32333
Land_Value($)        30462
Building_Value($)    30462
Total_Value($)       30462
Sale_Price($)            0
SaleDate                 0
SoldAsVacant             0
YearBuilt            32314
dtype: int64
#checking for NaN values in PropertyAddress and OwnerAddress
#There are 29 NaN values in PropertyAddress and 30462 NaN values in OwnerAddress.
​
df[df['PropertyAddress'].isnull()]
​
df['PropertyAddress'] = df['PropertyAddress'].fillna(df['OwnerAddress'])
​
df.isna().sum()
​
#NaN values for PropertyAddress has been reduced to 11. 
​
UniqueID                 0
ParcelID                 0
PropertyAddress         11
OwnerAddress         30462
LandUse                  0
OwnerName            31216
LegalReference           0
Acreage              30462
TaxDistrict          30462
Bedrooms             32320
FullBath             32202
HalfBath             32333
Land_Value($)        30462
Building_Value($)    30462
Total_Value($)       30462
Sale_Price($)            0
SaleDate                 0
SoldAsVacant             0
YearBuilt            32314
dtype: int64
#we can choose to delete/drop the 11 NaN Values(not correct data practice) or we can use the ParcelID to identify the address. 
​
#Creating a new df for ParcelID and Propertyaddress 
​
df2 = df[['ParcelID','PropertyAddress']]
​
df2.rename(columns = {'PropertyAddress':'PropertyAddress2'},inplace=True)
​
dup2 = df2.duplicated().sum()
​
print("This Dataset has",dup2,"duplicates")
This Dataset has 5839 duplicates
#so we are dropping the duplicates and NaN Values.  
​
df2.dropna(inplace=True)
​
#11 NaN values have been removed. 
​
df2.drop_duplicates(inplace=True)
​
#56477 values, 5839 have been dropped.
​
#checking for NaN and duplicates 
​
df2.isnull().sum()
​
df2.duplicated().sum()
0
#creating a df3 with just the NaN Values. 
​
df3 = df[df['PropertyAddress'].isnull()]
​
#Merging both df2 and df3.
​
df3 = df3.merge(df2,how='left')
​
df3['PropertyAddress'] = df3['PropertyAddress'].fillna(df3['PropertyAddress2'])
​
#Noticed that the new df3, has 12 rows, partly due to the new row index created. removing duplicate!
​
#merging df3 and df to get the remaining 11 values 
​
#df[df['PropertyAddress'].isnull()]
​
df3.drop_duplicates(inplace=True)
​
df3.drop([3],inplace=True)
​
df3.drop(columns=['ParcelID', 'PropertyAddress', 'OwnerAddress', 'LandUse',
       'OwnerName', 'LegalReference', 'Acreage', 'TaxDistrict', 'Bedrooms',
       'FullBath', 'HalfBath', 'Land_Value($)', 'Building_Value($)',
       'Total_Value($)', 'Sale_Price($)', 'SaleDate', 'SoldAsVacant',
       'YearBuilt'],inplace=True)
        
        
df4 = df.set_index('UniqueID ').join(df3.set_index('UniqueID '),lsuffix = '_Left',rsuffix = '_Right', how = 'outer')    
​
df4['PropertyAddress'] = df4['PropertyAddress'].fillna(df4['PropertyAddress2'])
​
#df4['PropertyAddress'] now has no NaN Value.
​
​
#cleaning the large NaN in Owneraddress in 2 ways (either drop the column "owneraddress" 
#since "propertyaddress" is the main address (and the major difference is in special characters "space and commas") 
#OR insert every propertyaddress to owneraddress
​
#1st option - insert every propertyaddress to owneraddress
#df4['OwnerAddress'] = df4['PropertyAddress']
#df4.isna().sum()
​
​
#2nd option - dropping the extra columns 
df4.drop(columns=['PropertyAddress2','OwnerAddress'],inplace=True)
​
#df4.isna().sum()
# Getting Sales year from sales date...This is because when doing our analysis, 
# we need to see the correlation between Yearly increment in housing sales.
​
df4['SaleYear'] = pd.to_datetime(df4['SaleDate']).dt.year
​
#changed the dtype of the year column from float to int64
df4[['YearBuilt']] = df4[['YearBuilt']].astype('int64',errors='ignore')
​
#fixing the 'N' and 'Y' on the 'Soldasvacant' column
df4['SoldAsVacant'] = df4['SoldAsVacant'].str.replace('Yes','Y')
df4['SoldAsVacant'] = df4['SoldAsVacant'].str.replace('No','N')
df4['SoldAsVacant'] = df4['SoldAsVacant'].str.replace('Y','Yes')
df4['SoldAsVacant'] = df4['SoldAsVacant'].str.replace('N','No')
​
df4
​
ParcelID	PropertyAddress	LandUse	OwnerName	LegalReference	Acreage	TaxDistrict	Bedrooms	FullBath	HalfBath	Land_Value($)	Building_Value($)	Total_Value($)	Sale_Price($)	SaleDate	SoldAsVacant	YearBuilt	SaleYear
UniqueID																		
0	105 03 0D 008.00	1208 3RD AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20130128-0008725	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN	132000	2013-01-24	No	NaN	2013
1	105 11 0 080.00	1802 STEWART PL, NASHVILLE	SINGLE FAMILY	STINSON, LAURA M.	20130118-0006337	0.17	URBAN SERVICES DISTRICT	2.00	1.00	0.00	32000.00	134400.00	168300.00	191500	2013-01-11	No	1941.00	2013
2	118 03 0 130.00	2761 ROSEDALE PL, NASHVILLE	SINGLE FAMILY	NUNES, JARED R.	20130124-0008033	0.11	CITY OF BERRY HILL	3.00	2.00	1.00	34000.00	157800.00	191800.00	202000	2013-01-18	No	2000.00	2013
3	119 01 0 479.00	224 PEACHTREE ST, NASHVILLE	SINGLE FAMILY	WHITFORD, KAREN	20130128-0008863	0.17	URBAN SERVICES DISTRICT	4.00	2.00	0.00	25000.00	243700.00	268700.00	32000	2013-01-18	No	1948.00	2013
4	119 05 0 186.00	316 LUTIE ST, NASHVILLE	SINGLE FAMILY	HENDERSON, JAMES P. & LYNN P.	20130131-0009929	0.34	URBAN SERVICES DISTRICT	2.00	1.00	0.00	25000.00	138100.00	164800.00	102000	2013-01-23	No	1910.00	2013
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
56631	093 13 0B 274.00	320 11TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161007-0106599	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN	210000	2016-10-06	No	NaN	2016
56632	093 13 0D 044.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161101-0115186	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN	338000	2016-10-25	No	NaN	2016
56633	093 13 0D 048.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161010-0106889	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN	742000	2016-10-04	No	NaN	2016
56634	093 13 0D 056.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161031-0114730	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN	320000	2016-10-26	No	NaN	2016
56635	093 13 0D 094.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161104-0117077	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN	330000	2016-10-27	No	NaN	2016
56477 rows × 18 columns

#seperating the address into street, county and State 
#df4.drop(columns=['Street','County','State'],inplace=True)
​
df4[['Street', 'County', 'State']] = df4['PropertyAddress'].str.split(',',expand = True)
​
df4
ParcelID	PropertyAddress	LandUse	OwnerName	LegalReference	Acreage	TaxDistrict	Bedrooms	FullBath	HalfBath	...	Building_Value($)	Total_Value($)	Sale_Price($)	SaleDate	SoldAsVacant	YearBuilt	SaleYear	Street	County	State
UniqueID																					
0	105 03 0D 008.00	1208 3RD AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20130128-0008725	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	132000	2013-01-24	No	NaN	2013	1208 3RD AVE S	NASHVILLE	None
1	105 11 0 080.00	1802 STEWART PL, NASHVILLE	SINGLE FAMILY	STINSON, LAURA M.	20130118-0006337	0.17	URBAN SERVICES DISTRICT	2.00	1.00	0.00	...	134400.00	168300.00	191500	2013-01-11	No	1941.00	2013	1802 STEWART PL	NASHVILLE	None
2	118 03 0 130.00	2761 ROSEDALE PL, NASHVILLE	SINGLE FAMILY	NUNES, JARED R.	20130124-0008033	0.11	CITY OF BERRY HILL	3.00	2.00	1.00	...	157800.00	191800.00	202000	2013-01-18	No	2000.00	2013	2761 ROSEDALE PL	NASHVILLE	None
3	119 01 0 479.00	224 PEACHTREE ST, NASHVILLE	SINGLE FAMILY	WHITFORD, KAREN	20130128-0008863	0.17	URBAN SERVICES DISTRICT	4.00	2.00	0.00	...	243700.00	268700.00	32000	2013-01-18	No	1948.00	2013	224 PEACHTREE ST	NASHVILLE	None
4	119 05 0 186.00	316 LUTIE ST, NASHVILLE	SINGLE FAMILY	HENDERSON, JAMES P. & LYNN P.	20130131-0009929	0.34	URBAN SERVICES DISTRICT	2.00	1.00	0.00	...	138100.00	164800.00	102000	2013-01-23	No	1910.00	2013	316 LUTIE ST	NASHVILLE	None
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
56631	093 13 0B 274.00	320 11TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161007-0106599	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	210000	2016-10-06	No	NaN	2016	320 11TH AVE S	NASHVILLE	None
56632	093 13 0D 044.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161101-0115186	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	338000	2016-10-25	No	NaN	2016	700 12TH AVE S	NASHVILLE	None
56633	093 13 0D 048.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161010-0106889	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	742000	2016-10-04	No	NaN	2016	700 12TH AVE S	NASHVILLE	None
56634	093 13 0D 056.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161031-0114730	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	320000	2016-10-26	No	NaN	2016	700 12TH AVE S	NASHVILLE	None
56635	093 13 0D 094.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161104-0117077	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	330000	2016-10-27	No	NaN	2016	700 12TH AVE S	NASHVILLE	None
56477 rows × 21 columns

df4.info()
<class 'pandas.core.frame.DataFrame'>
Index: 56477 entries, 0 to 56635
Data columns (total 21 columns):
 #   Column             Non-Null Count  Dtype         
---  ------             --------------  -----         
 0   ParcelID           56477 non-null  object        
 1   PropertyAddress    56477 non-null  object        
 2   LandUse            56477 non-null  object        
 3   OwnerName          25261 non-null  object        
 4   LegalReference     56477 non-null  object        
 5   Acreage            26015 non-null  float64       
 6   TaxDistrict        26015 non-null  object        
 7   Bedrooms           24157 non-null  float64       
 8   FullBath           24275 non-null  float64       
 9   HalfBath           24144 non-null  float64       
 10  Land_Value($)      26015 non-null  float64       
 11  Building_Value($)  26015 non-null  float64       
 12  Total_Value($)     26015 non-null  float64       
 13  Sale_Price($)      56477 non-null  int64         
 14  SaleDate           56477 non-null  datetime64[ns]
 15  SoldAsVacant       56477 non-null  object        
 16  YearBuilt          24163 non-null  float64       
 17  SaleYear           56477 non-null  int32         
 18  Street             56477 non-null  object        
 19  County             56477 non-null  object        
 20  State              18 non-null     object        
dtypes: datetime64[ns](1), float64(8), int32(1), int64(1), object(10)
memory usage: 9.3+ MB
#We Know that this is the housing data for the state of Tennessee, you can choose to fill the "State" column or remove it  
​
#df4[df4['State'].notnull()]
​
df4['State'] = df4['State'].fillna('TN')
​
df4
ParcelID	PropertyAddress	LandUse	OwnerName	LegalReference	Acreage	TaxDistrict	Bedrooms	FullBath	HalfBath	...	Building_Value($)	Total_Value($)	Sale_Price($)	SaleDate	SoldAsVacant	YearBuilt	SaleYear	Street	County	State
UniqueID																					
0	105 03 0D 008.00	1208 3RD AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20130128-0008725	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	132000	2013-01-24	No	NaN	2013	1208 3RD AVE S	NASHVILLE	TN
1	105 11 0 080.00	1802 STEWART PL, NASHVILLE	SINGLE FAMILY	STINSON, LAURA M.	20130118-0006337	0.17	URBAN SERVICES DISTRICT	2.00	1.00	0.00	...	134400.00	168300.00	191500	2013-01-11	No	1941.00	2013	1802 STEWART PL	NASHVILLE	TN
2	118 03 0 130.00	2761 ROSEDALE PL, NASHVILLE	SINGLE FAMILY	NUNES, JARED R.	20130124-0008033	0.11	CITY OF BERRY HILL	3.00	2.00	1.00	...	157800.00	191800.00	202000	2013-01-18	No	2000.00	2013	2761 ROSEDALE PL	NASHVILLE	TN
3	119 01 0 479.00	224 PEACHTREE ST, NASHVILLE	SINGLE FAMILY	WHITFORD, KAREN	20130128-0008863	0.17	URBAN SERVICES DISTRICT	4.00	2.00	0.00	...	243700.00	268700.00	32000	2013-01-18	No	1948.00	2013	224 PEACHTREE ST	NASHVILLE	TN
4	119 05 0 186.00	316 LUTIE ST, NASHVILLE	SINGLE FAMILY	HENDERSON, JAMES P. & LYNN P.	20130131-0009929	0.34	URBAN SERVICES DISTRICT	2.00	1.00	0.00	...	138100.00	164800.00	102000	2013-01-23	No	1910.00	2013	316 LUTIE ST	NASHVILLE	TN
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
56631	093 13 0B 274.00	320 11TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161007-0106599	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	210000	2016-10-06	No	NaN	2016	320 11TH AVE S	NASHVILLE	TN
56632	093 13 0D 044.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161101-0115186	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	338000	2016-10-25	No	NaN	2016	700 12TH AVE S	NASHVILLE	TN
56633	093 13 0D 048.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161010-0106889	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	742000	2016-10-04	No	NaN	2016	700 12TH AVE S	NASHVILLE	TN
56634	093 13 0D 056.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161031-0114730	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	320000	2016-10-26	No	NaN	2016	700 12TH AVE S	NASHVILLE	TN
56635	093 13 0D 094.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161104-0117077	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	330000	2016-10-27	No	NaN	2016	700 12TH AVE S	NASHVILLE	TN
56477 rows × 21 columns

THIS IS THE END OF THE CLEANING EXERCISE
Please note that while there are still NaN Values across the DataFrame. There is however; no way to properly fill in the missing details with the available information.

EXPLORATORY DATA ANALYSIS AND MACHINE LEARNING PREDICTION
WE WILL BE CREATING 2 DATAFRAME
The first will focus on the data that has values in Acreage, TaxDistrict, Bedrooms, Full Bath, Half Bath, Land Value, Building Value and Total Value. DataFrame will be called detailed dataframe (ddf).

The second data will focus on the columns that do not have NaN Values. DataFrame will be called Null Dataframe (ndf).

#First dataFrame with a detailed list of House features called Detailed DataFrame. -- EDA will be performed then 
#This will be used for machine learning 
#Targets will be number of Rooms and Total Values. Sales Value will also be a target
ddf = df4[df4['Total_Value($)'].notnull()]
​
​
#Second DataFrame that has only Address, sales year, sales date and sales price. -- Correlation between data must be checked
#if confirmed than this will be used for machine learning as well
#however, Soldvacant and taxdistrict will be used as features for this data with target being Sales values as well. 
#Creating a numerical representation for 'county','soldasvacant' and 'LandUse'
ndf = df4[df4['Total_Value($)'].isnull()]
ddf['YearBuilt'] = ddf[['YearBuilt']].astype('int64',errors='ignore')
​
ddf
ParcelID	PropertyAddress	LandUse	OwnerName	LegalReference	Acreage	TaxDistrict	Bedrooms	FullBath	HalfBath	...	Building_Value($)	Total_Value($)	Sale_Price($)	SaleDate	SoldAsVacant	YearBuilt	SaleYear	Street	County	State
UniqueID																					
1	105 11 0 080.00	1802 STEWART PL, NASHVILLE	SINGLE FAMILY	STINSON, LAURA M.	20130118-0006337	0.17	URBAN SERVICES DISTRICT	2.00	1.00	0.00	...	134400.00	168300.00	191500	2013-01-11	No	1941.00	2013	1802 STEWART PL	NASHVILLE	TN
2	118 03 0 130.00	2761 ROSEDALE PL, NASHVILLE	SINGLE FAMILY	NUNES, JARED R.	20130124-0008033	0.11	CITY OF BERRY HILL	3.00	2.00	1.00	...	157800.00	191800.00	202000	2013-01-18	No	2000.00	2013	2761 ROSEDALE PL	NASHVILLE	TN
3	119 01 0 479.00	224 PEACHTREE ST, NASHVILLE	SINGLE FAMILY	WHITFORD, KAREN	20130128-0008863	0.17	URBAN SERVICES DISTRICT	4.00	2.00	0.00	...	243700.00	268700.00	32000	2013-01-18	No	1948.00	2013	224 PEACHTREE ST	NASHVILLE	TN
4	119 05 0 186.00	316 LUTIE ST, NASHVILLE	SINGLE FAMILY	HENDERSON, JAMES P. & LYNN P.	20130131-0009929	0.34	URBAN SERVICES DISTRICT	2.00	1.00	0.00	...	138100.00	164800.00	102000	2013-01-23	No	1910.00	2013	316 LUTIE ST	NASHVILLE	TN
5	119 05 0 387.00	2626 FOSTER AVE, NASHVILLE	SINGLE FAMILY	MILLER, JORDAN	20130118-0006110	0.17	URBAN SERVICES DISTRICT	2.00	1.00	0.00	...	86100.00	113300.00	93736	2013-01-04	No	1945.00	2013	2626 FOSTER AVE	NASHVILLE	TN
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
56607	176 09 0 003.00	4964 HICKORY WOODS E, ANTIOCH	SINGLE FAMILY	CHHAY, CHOWAN & NIM, PHALLY	20161031-0114817	0.23	URBAN SERVICES DISTRICT	3.00	3.00	0.00	...	159300.00	184300.00	236000	2016-10-28	No	1995.00	2016	4964 HICKORY WOODS E	ANTIOCH	TN
56612	081 16 0 197.00	1017 MONROE ST, NASHVILLE	VACANT RESIDENTIAL LAND	ZHANG, JUN YEN	20161026-0113388	0.17	URBAN SERVICES DISTRICT	NaN	NaN	NaN	...	0.00	40000.00	231500	2016-10-24	Yes	NaN	2016	1017 MONROE ST	NASHVILLE	TN
56614	082 05 0 040.00	1625 5TH AVE N, NASHVILLE	SINGLE FAMILY	GLAUS, WILLIAM D. SR.	20161102-0115988	0.15	URBAN SERVICES DISTRICT	3.00	2.00	1.00	...	204100.00	256000.00	466000	2016-10-28	No	2004.00	2016	1625 5TH AVE N	NASHVILLE	TN
56615	082 05 0 058.00	1614 5TH AVE N, NASHVILLE	SINGLE FAMILY	DUNN, JEFFREY J. & HOWE, TRICIA L.	20161101-0115366	0.19	URBAN SERVICES DISTRICT	4.00	3.00	1.00	...	295900.00	351600.00	685000	2016-10-26	No	2005.00	2016	1614 5TH AVE N	NASHVILLE	TN
56616	082 05 0 098.00	1709 3RD AVE N, NASHVILLE	VACANT RESIDENTIAL LAND	NaN	20161017-0109149	0.20	URBAN SERVICES DISTRICT	3.00	1.00	0.00	...	5100.00	46000.00	280000	2016-10-12	No	1899.00	2016	1709 3RD AVE N	NASHVILLE	TN
26015 rows × 21 columns

ndf
ParcelID	PropertyAddress	LandUse	OwnerName	LegalReference	Acreage	TaxDistrict	Bedrooms	FullBath	HalfBath	...	Building_Value($)	Total_Value($)	Sale_Price($)	SaleDate	SoldAsVacant	YearBuilt	SaleYear	Street	County	State
UniqueID																					
0	105 03 0D 008.00	1208 3RD AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20130128-0008725	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	132000	2013-01-24	No	NaN	2013	1208 3RD AVE S	NASHVILLE	TN
6	119 10 0A 104.00	104 PRESCOTT PL, NASHVILLE	RESIDENTIAL CONDO	NaN	20130109-0002881	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	64900	2013-01-07	No	NaN	2013	104 PRESCOTT PL	NASHVILLE	TN
17	147 03 0B 089.00	370 WALLACE RD, NASHVILLE	RESIDENTIAL CONDO	NaN	20130129-0009357	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	31416	2013-01-29	No	NaN	2013	370 WALLACE RD	NASHVILLE	TN
18	147 12 0A 109.00	109 NORTHCREST COMMONS CIR, NASHVILLE	RESIDENTIAL CONDO	NaN	20130117-0005497	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	127500	2013-01-16	No	NaN	2013	109 NORTHCREST COMMONS CIR	NASHVILLE	TN
25	160 11 0A 088.00	5510 HEARTHSTONE LN, BRENTWOOD	SINGLE FAMILY	NaN	20130117-0005616	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	270000	2013-01-15	No	NaN	2013	5510 HEARTHSTONE LN	BRENTWOOD	TN
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
56631	093 13 0B 274.00	320 11TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161007-0106599	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	210000	2016-10-06	No	NaN	2016	320 11TH AVE S	NASHVILLE	TN
56632	093 13 0D 044.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161101-0115186	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	338000	2016-10-25	No	NaN	2016	700 12TH AVE S	NASHVILLE	TN
56633	093 13 0D 048.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161010-0106889	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	742000	2016-10-04	No	NaN	2016	700 12TH AVE S	NASHVILLE	TN
56634	093 13 0D 056.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161031-0114730	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	320000	2016-10-26	No	NaN	2016	700 12TH AVE S	NASHVILLE	TN
56635	093 13 0D 094.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161104-0117077	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	330000	2016-10-27	No	NaN	2016	700 12TH AVE S	NASHVILLE	TN
30462 rows × 21 columns

print ("There are %.0f" %ndf['LandUse'].nunique(), "unique types of land use and %.0f" %ndf['County'].nunique(), "uniques counties in our dataframe")
There are 18 unique types of land use and 12 uniques counties in our dataframe
#the reason for the statement above is because we will be 
ndf.info()
<class 'pandas.core.frame.DataFrame'>
Index: 30462 entries, 0 to 56635
Data columns (total 21 columns):
 #   Column             Non-Null Count  Dtype         
---  ------             --------------  -----         
 0   ParcelID           30462 non-null  object        
 1   PropertyAddress    30462 non-null  object        
 2   LandUse            30462 non-null  object        
 3   OwnerName          0 non-null      object        
 4   LegalReference     30462 non-null  object        
 5   Acreage            0 non-null      float64       
 6   TaxDistrict        0 non-null      object        
 7   Bedrooms           0 non-null      float64       
 8   FullBath           0 non-null      float64       
 9   HalfBath           0 non-null      float64       
 10  Land_Value($)      0 non-null      float64       
 11  Building_Value($)  0 non-null      float64       
 12  Total_Value($)     0 non-null      float64       
 13  Sale_Price($)      30462 non-null  int64         
 14  SaleDate           30462 non-null  datetime64[ns]
 15  SoldAsVacant       30462 non-null  object        
 16  YearBuilt          0 non-null      float64       
 17  SaleYear           30462 non-null  int32         
 18  Street             30462 non-null  object        
 19  County             30462 non-null  object        
 20  State              30462 non-null  object        
dtypes: datetime64[ns](1), float64(8), int32(1), int64(1), object(10)
memory usage: 5.0+ MB
Exploratory Analysis on DDF
ddf.info()
<class 'pandas.core.frame.DataFrame'>
Index: 26015 entries, 1 to 56616
Data columns (total 21 columns):
 #   Column             Non-Null Count  Dtype         
---  ------             --------------  -----         
 0   ParcelID           26015 non-null  object        
 1   PropertyAddress    26015 non-null  object        
 2   LandUse            26015 non-null  object        
 3   OwnerName          25261 non-null  object        
 4   LegalReference     26015 non-null  object        
 5   Acreage            26015 non-null  float64       
 6   TaxDistrict        26015 non-null  object        
 7   Bedrooms           24157 non-null  float64       
 8   FullBath           24275 non-null  float64       
 9   HalfBath           24144 non-null  float64       
 10  Land_Value($)      26015 non-null  float64       
 11  Building_Value($)  26015 non-null  float64       
 12  Total_Value($)     26015 non-null  float64       
 13  Sale_Price($)      26015 non-null  int64         
 14  SaleDate           26015 non-null  datetime64[ns]
 15  SoldAsVacant       26015 non-null  object        
 16  YearBuilt          24163 non-null  float64       
 17  SaleYear           26015 non-null  int32         
 18  Street             26015 non-null  object        
 19  County             26015 non-null  object        
 20  State              26015 non-null  object        
dtypes: datetime64[ns](1), float64(8), int32(1), int64(1), object(10)
memory usage: 4.3+ MB
#dropping redundant columns: 'ParcelID','PropertyAddress','OwnerName','LegalReference','State'
ddf.describe(include= np.number)
Acreage	Bedrooms	FullBath	HalfBath	Land_Value($)	Building_Value($)	Total_Value($)	Sale_Price($)	YearBuilt	SaleYear
count	26015.00	24157.00	24275.00	24144.00	26015.00	26015.00	26015.00	26015.00	24163.00	26015.00
mean	0.50	3.09	1.89	0.28	69068.56	160784.68	232375.40	280722.81	1963.74	2014.59
std	1.57	0.85	0.96	0.49	106040.13	206799.85	281064.35	374630.38	26.54	1.08
min	0.01	0.00	0.00	0.00	100.00	0.00	100.00	50.00	1799.00	2013.00
25%	0.18	3.00	1.00	0.00	21000.00	75900.00	102800.00	122000.00	1948.00	2014.00
50%	0.27	3.00	2.00	0.00	28800.00	111400.00	148500.00	184000.00	1960.00	2015.00
75%	0.45	3.00	2.00	1.00	60000.00	180700.00	268350.00	325000.00	1983.00	2016.00
max	160.06	11.00	10.00	3.00	2772000.00	12971800.00	13940400.00	12350000.00	2017.00	2019.00
ddf.describe(include= 'object')
ParcelID	PropertyAddress	LandUse	OwnerName	LegalReference	TaxDistrict	SoldAsVacant	Street	County	State
count	26015	26015	26015	25261	26015	26015	26015	26015	26015	26015
unique	22432	23253	34	19713	25209	7	2	23231	12	2
top	081 07 0 103.00	0 MCKINLEY ST, NASHVILLE	SINGLE FAMILY	JRG PROPERTIES, LLC	20151002-0100496	URBAN SERVICES DISTRICT	No	0 MCKINLEY ST	NASHVILLE	TN
freq	4	7	21875	26	24	20024	24784	9	20700	25997
ddf.columns
Index(['ParcelID', 'PropertyAddress', 'LandUse', 'OwnerName', 'LegalReference',
       'Acreage', 'TaxDistrict', 'Bedrooms', 'FullBath', 'HalfBath',
       'Land_Value($)', 'Building_Value($)', 'Total_Value($)', 'Sale_Price($)',
       'SaleDate', 'SoldAsVacant', 'YearBuilt', 'SaleYear', 'Street', 'County',
       'State'],
      dtype='object')
#ddf['TaxDistrict'].unique()
​
#ddf['County'].unique()
​
#ddf['State'].unique()
​
ddf['LandUse'].unique()
array(['SINGLE FAMILY', 'VACANT RES LAND', 'DUPLEX', 'ZERO LOT LINE',
       'TRIPLEX', 'RESIDENTIAL COMBO/MISC', 'CHURCH', 'QUADPLEX',
       'VACANT COMMERCIAL LAND', 'STRIP SHOPPING CENTER',
       'VACANT RURAL LAND', 'DORMITORY/BOARDING HOUSE', 'MOBILE HOME',
       'PARSONAGE', 'SPLIT CLASS', 'GREENBELT',
       'VACANT ZONED MULTI FAMILY', 'PARKING LOT',
       'OFFICE BLDG (ONE OR TWO STORIES)', 'VACANT RESIDENTIAL LAND',
       'FOREST', 'CONVENIENCE MARKET WITHOUT GAS',
       'CLUB/UNION HALL/LODGE', 'LIGHT MANUFACTURING',
       'ONE STORY GENERAL RETAIL STORE', 'DAY CARE CENTER',
       'GREENBELT/RES_x000D_\nGRRENBELT/RES',
       'APARTMENT: LOW RISE (BUILT SINCE 1960)', 'VACANT RESIENTIAL LAND',
       'TERMINAL/DISTRIBUTION WAREHOUSE', 'NON-PROFIT CHARITABLE SERVICE',
       'METRO OTHER THAN OFC, SCHOOL,HOSP, OR PARK', 'NIGHTCLUB/LOUNGE',
       'MORTUARY/CEMETERY'], dtype=object)
#Changing 'SoldasVacant' into Binery....second option is to create dummy numbers 
def Binery(x): 
    if x == 'No': 
        return (0)
    else: 
        return (1)
    
ddf['SoldAsVacant'] = ddf['SoldAsVacant'].apply(Binery)
​
ddf
ParcelID	PropertyAddress	LandUse	OwnerName	LegalReference	Acreage	TaxDistrict	Bedrooms	FullBath	HalfBath	...	Building_Value($)	Total_Value($)	Sale_Price($)	SaleDate	SoldAsVacant	YearBuilt	SaleYear	Street	County	State
UniqueID																					
1	105 11 0 080.00	1802 STEWART PL, NASHVILLE	SINGLE FAMILY	STINSON, LAURA M.	20130118-0006337	0.17	URBAN SERVICES DISTRICT	2.00	1.00	0.00	...	134400.00	168300.00	191500	2013-01-11	0	1941.00	2013	1802 STEWART PL	NASHVILLE	TN
2	118 03 0 130.00	2761 ROSEDALE PL, NASHVILLE	SINGLE FAMILY	NUNES, JARED R.	20130124-0008033	0.11	CITY OF BERRY HILL	3.00	2.00	1.00	...	157800.00	191800.00	202000	2013-01-18	0	2000.00	2013	2761 ROSEDALE PL	NASHVILLE	TN
3	119 01 0 479.00	224 PEACHTREE ST, NASHVILLE	SINGLE FAMILY	WHITFORD, KAREN	20130128-0008863	0.17	URBAN SERVICES DISTRICT	4.00	2.00	0.00	...	243700.00	268700.00	32000	2013-01-18	0	1948.00	2013	224 PEACHTREE ST	NASHVILLE	TN
4	119 05 0 186.00	316 LUTIE ST, NASHVILLE	SINGLE FAMILY	HENDERSON, JAMES P. & LYNN P.	20130131-0009929	0.34	URBAN SERVICES DISTRICT	2.00	1.00	0.00	...	138100.00	164800.00	102000	2013-01-23	0	1910.00	2013	316 LUTIE ST	NASHVILLE	TN
5	119 05 0 387.00	2626 FOSTER AVE, NASHVILLE	SINGLE FAMILY	MILLER, JORDAN	20130118-0006110	0.17	URBAN SERVICES DISTRICT	2.00	1.00	0.00	...	86100.00	113300.00	93736	2013-01-04	0	1945.00	2013	2626 FOSTER AVE	NASHVILLE	TN
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
56607	176 09 0 003.00	4964 HICKORY WOODS E, ANTIOCH	SINGLE FAMILY	CHHAY, CHOWAN & NIM, PHALLY	20161031-0114817	0.23	URBAN SERVICES DISTRICT	3.00	3.00	0.00	...	159300.00	184300.00	236000	2016-10-28	0	1995.00	2016	4964 HICKORY WOODS E	ANTIOCH	TN
56612	081 16 0 197.00	1017 MONROE ST, NASHVILLE	VACANT RESIDENTIAL LAND	ZHANG, JUN YEN	20161026-0113388	0.17	URBAN SERVICES DISTRICT	NaN	NaN	NaN	...	0.00	40000.00	231500	2016-10-24	1	NaN	2016	1017 MONROE ST	NASHVILLE	TN
56614	082 05 0 040.00	1625 5TH AVE N, NASHVILLE	SINGLE FAMILY	GLAUS, WILLIAM D. SR.	20161102-0115988	0.15	URBAN SERVICES DISTRICT	3.00	2.00	1.00	...	204100.00	256000.00	466000	2016-10-28	0	2004.00	2016	1625 5TH AVE N	NASHVILLE	TN
56615	082 05 0 058.00	1614 5TH AVE N, NASHVILLE	SINGLE FAMILY	DUNN, JEFFREY J. & HOWE, TRICIA L.	20161101-0115366	0.19	URBAN SERVICES DISTRICT	4.00	3.00	1.00	...	295900.00	351600.00	685000	2016-10-26	0	2005.00	2016	1614 5TH AVE N	NASHVILLE	TN
56616	082 05 0 098.00	1709 3RD AVE N, NASHVILLE	VACANT RESIDENTIAL LAND	NaN	20161017-0109149	0.20	URBAN SERVICES DISTRICT	3.00	1.00	0.00	...	5100.00	46000.00	280000	2016-10-12	0	1899.00	2016	1709 3RD AVE N	NASHVILLE	TN
26015 rows × 21 columns

#looking for potential correlations...Grouping by 'LandUse','TaxDistrict','SoldAsVacant' and 'County'. 
#landuse_df = ddf.drop(columns=['ParcelID','PropertyAddress','OwnerName','LegalReference','TaxDistrict','State','Street'])
​
Tax_df = ddf.drop(columns=['ParcelID','PropertyAddress','OwnerName','LegalReference','LandUse','State','Street','County'])
​
def taxdistriceNr (x): 
    if x == 'URBAN SERVICES DISTRICT': 
        return (0)
    elif x == 'CITY OF BERRY HILL': 
        return (1)
    elif x == 'GENERAL SERVICES DISTRICT': 
        return (2)
    elif x == 'CITY OF BELLE MEADE': 
        return (3)
    elif x == 'CITY OF OAK HILL': 
        return (4)
    elif x == 'CITY OF FOREST HILL': 
        return (5)
    else:
        return (6)
​
​
​
Tax_df['TaxDistrict'] = Tax_df['TaxDistrict'].apply(taxdistriceNr)
​
corr1 = Tax_df.corr()
​
​
#from the heatmap, we know that soldasvacant does not have any correlation  with our dataFrame.
​
#corr1.mean()
​
plt.imshow(corr1)
​
#for i in range(len(xlabs)):
#    for j in range(len(ylabs)):
#        text = ax.text(j, i, round(corr1[i, j], 1), 
#                       ha = "center", va = "center")
        
#cbar = ax.figure.       
<matplotlib.image.AxesImage at 0x1ef15538290>

County_df = ddf.drop(columns=['ParcelID','PropertyAddress','OwnerName','LegalReference','LandUse','State','Street','TaxDistrict'])
​
def CountyNr (x): 
    if x == ' NASHVILLE': 
        return (0)
    elif x == ' ANTIOCH': 
        return (1)
    elif x == ' BRENTWOOD': 
        return (2)
    elif x == ' MADISON': 
        return (3)
    elif x == ' OLD HICKORY': 
        return (4)
    elif x == ' HERMITAGE': 
        return (5)
    elif x == ' GOODLETTSVILLE': 
        return (6)
    elif x == ' WHITES CREEK': 
        return (7)
    elif x == ' JOELTON': 
        return (8)
    elif x == ' MOUNT JULIET': 
        return (9)
    elif x == ' NOLENSVILLE': 
        return (10)
    else:
        return (11)
​
​
​
County_df['County'] = County_df['County'].apply(CountyNr)
​
corr2 = County_df.corr()
corr2
Acreage	Bedrooms	FullBath	HalfBath	Land_Value($)	Building_Value($)	Total_Value($)	Sale_Price($)	SaleDate	SoldAsVacant	YearBuilt	SaleYear	County
Acreage	1.00	0.15	0.17	0.04	0.30	0.13	0.21	0.20	0.00	0.09	0.02	-0.00	0.07
Bedrooms	0.15	1.00	0.61	0.19	0.34	0.45	0.45	0.37	-0.04	0.05	0.16	-0.03	-0.00
FullBath	0.17	0.61	1.00	0.09	0.51	0.59	0.63	0.51	-0.06	0.05	0.29	-0.05	-0.06
HalfBath	0.04	0.19	0.09	1.00	0.18	0.35	0.32	0.24	-0.02	0.09	0.26	-0.02	-0.05
Land_Value($)	0.30	0.34	0.51	0.18	1.00	0.52	0.77	0.60	-0.05	0.03	-0.02	-0.05	-0.15
Building_Value($)	0.13	0.45	0.59	0.35	0.52	1.00	0.95	0.57	-0.08	-0.04	0.19	-0.08	-0.12
Total_Value($)	0.21	0.45	0.63	0.32	0.77	0.95	1.00	0.66	-0.08	-0.01	0.14	-0.08	-0.14
Sale_Price($)	0.20	0.37	0.51	0.24	0.60	0.57	0.66	1.00	0.06	-0.04	0.04	0.06	-0.14
SaleDate	0.00	-0.04	-0.06	-0.02	-0.05	-0.08	-0.08	0.06	1.00	0.02	0.01	0.97	0.03
SoldAsVacant	0.09	0.05	0.05	0.09	0.03	-0.04	-0.01	-0.04	0.02	1.00	0.24	0.01	-0.03
YearBuilt	0.02	0.16	0.29	0.26	-0.02	0.19	0.14	0.04	0.01	0.24	1.00	0.01	0.11
SaleYear	-0.00	-0.03	-0.05	-0.02	-0.05	-0.08	-0.08	0.06	0.97	0.01	0.01	1.00	0.02
County	0.07	-0.00	-0.06	-0.05	-0.15	-0.12	-0.14	-0.14	0.03	-0.03	0.11	0.02	1.00
plt.imshow(corr2)
<matplotlib.image.AxesImage at 0x1ef15201b90>

landuse_df = ddf.drop(columns=['ParcelID','PropertyAddress','OwnerName','LegalReference','TaxDistrict','State','Street','County'])
​
#this works as well
#landuse_df['new_id'] = pd.factorize(landuse_df['LandUse'])[0]
#landuse_df['new_id'].unique()
​
#Assigning numericals to unique cells in a columns -- s0 rather than use Def, we are using groupby 
landuse_df['LandUse'] = landuse_df.groupby(landuse_df.LandUse.tolist(),sort=False).ngroup()
corr3 = landuse_df.corr()
corr3
LandUse	Acreage	Bedrooms	FullBath	HalfBath	Land_Value($)	Building_Value($)	Total_Value($)	Sale_Price($)	SaleDate	SoldAsVacant	YearBuilt	SaleYear
LandUse	1.00	0.12	0.05	0.03	0.06	-0.01	-0.11	-0.08	0.04	0.12	0.62	0.20	0.12
Acreage	0.12	1.00	0.15	0.17	0.04	0.30	0.13	0.21	0.20	0.00	0.09	0.02	-0.00
Bedrooms	0.05	0.15	1.00	0.61	0.19	0.34	0.45	0.45	0.37	-0.04	0.05	0.16	-0.03
FullBath	0.03	0.17	0.61	1.00	0.09	0.51	0.59	0.63	0.51	-0.06	0.05	0.29	-0.05
HalfBath	0.06	0.04	0.19	0.09	1.00	0.18	0.35	0.32	0.24	-0.02	0.09	0.26	-0.02
Land_Value($)	-0.01	0.30	0.34	0.51	0.18	1.00	0.52	0.77	0.60	-0.05	0.03	-0.02	-0.05
Building_Value($)	-0.11	0.13	0.45	0.59	0.35	0.52	1.00	0.95	0.57	-0.08	-0.04	0.19	-0.08
Total_Value($)	-0.08	0.21	0.45	0.63	0.32	0.77	0.95	1.00	0.66	-0.08	-0.01	0.14	-0.08
Sale_Price($)	0.04	0.20	0.37	0.51	0.24	0.60	0.57	0.66	1.00	0.06	-0.04	0.04	0.06
SaleDate	0.12	0.00	-0.04	-0.06	-0.02	-0.05	-0.08	-0.08	0.06	1.00	0.02	0.01	0.97
SoldAsVacant	0.62	0.09	0.05	0.05	0.09	0.03	-0.04	-0.01	-0.04	0.02	1.00	0.24	0.01
YearBuilt	0.20	0.02	0.16	0.29	0.26	-0.02	0.19	0.14	0.04	0.01	0.24	1.00	0.01
SaleYear	0.12	-0.00	-0.03	-0.05	-0.02	-0.05	-0.08	-0.08	0.06	0.97	0.01	0.01	1.00
plt.imshow(corr3)
<matplotlib.image.AxesImage at 0x1ef15077bd0>

fig, ax = plt.subplots(1, figsize = (20,8))
ax.grid()
fig.autofmt_xdate()
sns.countplot(data=ddf,x='County')
plt.show()
#From this dataset, we can see that we have less data from other counties as 90% is from NASHVILLE.
#This may also skrew our data as factors like Acreage, YearBuilt and TaxDistrict will be largely influenced 
#by the county behaviour. 
​
fig, ax = plt.subplots(1, figsize = (20,8))
ax.grid()
fig.autofmt_xdate()
sns.countplot(data=ddf,x='County')
plt.show()

columns = ['ParcelID','PropertyAddress','OwnerName','LegalReference','SaleDate','Street','State']
#So looking at the individual columns ('LandUse','County','TaxDistrict','SoldAsVacant') and their correlations, 
#we will look at the whole data and its correlation 
​
#ddf
​
#Dropping columns: PercelID,PropertyAddress,OwnerName, LegalReference, SalesDate,State,Street
ddf = ddf.drop(columns = ['ParcelID','PropertyAddress','OwnerName','LegalReference','SaleDate','Street','State'])
ddf['LandUse'] = ddf.groupby(ddf.LandUse.tolist(),sort=False).ngroup()

# Now we are changing the string statements to numerical for County, Taxdistrict and Landuse 
​
#first we have to identify the unique values in County, Taxdistrict and landuse. 
​
#ddf['County'].unique() - array([' NASHVILLE', ' ANTIOCH', ' BRENTWOOD', ' MADISON', ' OLD HICKORY',
       #' HERMITAGE', ' GOODLETTSVILLE', ' WHITES CREEK', ' JOELTON',
       #' MOUNT JULIET', ' NOLENSVILLE', ' BELLEVUE'], dtype=object)
​
#ddf['TaxDistrict'].unique() - array(['URBAN SERVICES DISTRICT', 'CITY OF BERRY HILL',
       #'GENERAL SERVICES DISTRICT', 'CITY OF BELLE MEADE',
       #'CITY OF OAK HILL', 'CITY OF FOREST HILLS',
       #'CITY OF GOODLETTSVILLE'], dtype=object)   
    
#ddf['LandUse'].unique() - array(['SINGLE FAMILY', 'VACANT RES LAND', 'DUPLEX', 'ZERO LOT LINE',
       #'TRIPLEX', 'RESIDENTIAL COMBO/MISC', 'CHURCH', 'QUADPLEX','VACANT COMMERCIAL LAND', 'STRIP SHOPPING CENTER',
       #'VACANT RURAL LAND', 'DORMITORY/BOARDING HOUSE', 'MOBILE HOME','PARSONAGE', 'SPLIT CLASS', 'GREENBELT',
       #'VACANT ZONED MULTI FAMILY', 'PARKING LOT','OFFICE BLDG (ONE OR TWO STORIES)', 'VACANT RESIDENTIAL LAND',
       #'FOREST', 'CONVENIENCE MARKET WITHOUT GAS','CLUB/UNION HALL/LODGE', 'LIGHT MANUFACTURING',
       #'ONE STORY GENERAL RETAIL STORE', 'DAY CARE CENTER','GREENBELT/RES_x000D_\nGRRENBELT/RES',
       #'APARTMENT: LOW RISE (BUILT SINCE 1960)', 'VACANT RESIENTIAL LAND',
       #'TERMINAL/DISTRIBUTION WAREHOUSE', 'NON-PROFIT CHARITABLE SERVICE',
       #'METRO OTHER THAN OFC, SCHOOL,HOSP, OR PARK', 'NIGHTCLUB/LOUNGE',
       #'MORTUARY/CEMETERY'], dtype=object)
    
ddf['LandUse'] = ddf.groupby(ddf.LandUse.tolist(),sort=False).ngroup()
​
ddf['TaxDistrict'] = ddf.groupby(ddf.TaxDistrict.tolist(),sort=False).ngroup()
​
ddf['County'] = ddf.groupby(ddf.County.tolist(),sort=False).ngroup()
    
ddf.corr()
LandUse	Acreage	TaxDistrict	Bedrooms	FullBath	HalfBath	Land_Value($)	Building_Value($)	Total_Value($)	Sale_Price($)	SoldAsVacant	YearBuilt	SaleYear	County
LandUse	1.00	0.12	0.01	0.05	0.03	0.06	-0.01	-0.11	-0.08	0.04	0.62	0.20	0.12	-0.01
Acreage	0.12	1.00	0.15	0.15	0.17	0.04	0.30	0.13	0.21	0.20	0.09	0.02	-0.00	0.07
TaxDistrict	0.01	0.15	1.00	0.12	0.17	0.04	0.26	0.11	0.18	0.11	0.01	0.13	0.01	0.61
Bedrooms	0.05	0.15	0.12	1.00	0.61	0.19	0.34	0.45	0.45	0.37	0.05	0.16	-0.03	-0.00
FullBath	0.03	0.17	0.17	0.61	1.00	0.09	0.51	0.59	0.63	0.51	0.05	0.29	-0.05	-0.06
HalfBath	0.06	0.04	0.04	0.19	0.09	1.00	0.18	0.35	0.32	0.24	0.09	0.26	-0.02	-0.05
Land_Value($)	-0.01	0.30	0.26	0.34	0.51	0.18	1.00	0.52	0.77	0.60	0.03	-0.02	-0.05	-0.15
Building_Value($)	-0.11	0.13	0.11	0.45	0.59	0.35	0.52	1.00	0.95	0.57	-0.04	0.19	-0.08	-0.12
Total_Value($)	-0.08	0.21	0.18	0.45	0.63	0.32	0.77	0.95	1.00	0.66	-0.01	0.14	-0.08	-0.14
Sale_Price($)	0.04	0.20	0.11	0.37	0.51	0.24	0.60	0.57	0.66	1.00	-0.04	0.04	0.06	-0.14
SoldAsVacant	0.62	0.09	0.01	0.05	0.05	0.09	0.03	-0.04	-0.01	-0.04	1.00	0.24	0.01	-0.03
YearBuilt	0.20	0.02	0.13	0.16	0.29	0.26	-0.02	0.19	0.14	0.04	0.24	1.00	0.01	0.11
SaleYear	0.12	-0.00	0.01	-0.03	-0.05	-0.02	-0.05	-0.08	-0.08	0.06	0.01	0.01	1.00	0.02
County	-0.01	0.07	0.61	-0.00	-0.06	-0.05	-0.15	-0.12	-0.14	-0.14	-0.03	0.11	0.02	1.00
#from the correlation, we see that Acreage, TaxDistrict, HalfBath,YearBuilt and SaleYear dont have strong connection to Sales value.
​
sns.pairplot(ddf,palette='coolwarm')
<seaborn.axisgrid.PairGrid at 0x1ef15530790>

#From the data, we have 4 columns that are closely tied to the total values (Land Value, Sales Price, Building Value, 
#Fullbath and Bedroom all have a correlation of more than 60%)
sns.scatterplot(data = ddf,y = 'Total_Value($)',x = 'Building_Value($)',palette='coolwarm')
<Axes: xlabel='Building_Value($)', ylabel='Total_Value($)'>

#From the data, we have 4 columns that are closely tied to the total values (Land Value, Sales Price, Building Value, 
#Fullbath and Bedroom all have a correlation of more than 60%)
#From the data, we have 4 columns that are closely tied to the total values (Land Value, Sales Price, Building Value, 
#Fullbath and Bedroom all have a correlation of more than 60%)
sns.scatterplot(data = ddf,y = 'Total_Value($)',x = 'Land_Value($)',palette='coolwarm')
<Axes: xlabel='Land_Value($)', ylabel='Total_Value($)'>

sns.scatterplot(data = ddf,y = 'Total_Value($)',x = 'FullBath',palette='coolwarm')
sns.scatterplot(data = ddf,y = 'Total_Value($)',x = 'FullBath',palette='coolwarm')
<Axes: xlabel='FullBath', ylabel='Total_Value($)'>

sns.scatterplot(data = ddf,y = 'Total_Value($)',x = 'Bedrooms',palette='coolwarm')
<Axes: xlabel='Bedrooms', ylabel='Total_Value($)'>

palette='coolwarm'
sns.scatterplot(data = ddf,y = 'Sale_Price($)',x = 'Total_Value($)',palette='coolwarm')
<Axes: xlabel='Total_Value($)', ylabel='Sale_Price($)'>

is
#Findings: Houses values are based off building value the most, while factors like Land_value, bedroom/bathroom are also big indicators. 
​
#Unexpected: SoldasVacant and County/street do not show much impact on the sales price, for this state.
​
#one thing i am lookin for is the difference in sales value per year 
​
sns.boxplot(data=ddf,y='Sale_Price($)',x='SaleYear',palette='coolwarm')
​
#2019 only has one recorded sale. so it is an outlier. However, we can see there is steady increase in sales prices. 
​
<Axes: xlabel='SaleYear', ylabel='Sale_Price($)'>

WORKING ON DATAFRAME 2 -- NULL DATAFRAME 
ndf
ParcelID	PropertyAddress	LandUse	OwnerName	LegalReference	Acreage	TaxDistrict	Bedrooms	FullBath	HalfBath	...	Building_Value($)	Total_Value($)	Sale_Price($)	SaleDate	SoldAsVacant	YearBuilt	SaleYear	Street	County	State
UniqueID																					
0	105 03 0D 008.00	1208 3RD AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20130128-0008725	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	132000	2013-01-24	No	NaN	2013	1208 3RD AVE S	NASHVILLE	TN
6	119 10 0A 104.00	104 PRESCOTT PL, NASHVILLE	RESIDENTIAL CONDO	NaN	20130109-0002881	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	64900	2013-01-07	No	NaN	2013	104 PRESCOTT PL	NASHVILLE	TN
17	147 03 0B 089.00	370 WALLACE RD, NASHVILLE	RESIDENTIAL CONDO	NaN	20130129-0009357	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	31416	2013-01-29	No	NaN	2013	370 WALLACE RD	NASHVILLE	TN
18	147 12 0A 109.00	109 NORTHCREST COMMONS CIR, NASHVILLE	RESIDENTIAL CONDO	NaN	20130117-0005497	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	127500	2013-01-16	No	NaN	2013	109 NORTHCREST COMMONS CIR	NASHVILLE	TN
25	160 11 0A 088.00	5510 HEARTHSTONE LN, BRENTWOOD	SINGLE FAMILY	NaN	20130117-0005616	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	270000	2013-01-15	No	NaN	2013	5510 HEARTHSTONE LN	BRENTWOOD	TN
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
56631	093 13 0B 274.00	320 11TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161007-0106599	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	210000	2016-10-06	No	NaN	2016	320 11TH AVE S	NASHVILLE	TN
56632	093 13 0D 044.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161101-0115186	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	338000	2016-10-25	No	NaN	2016	700 12TH AVE S	NASHVILLE	TN
56633	093 13 0D 048.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161010-0106889	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	742000	2016-10-04	No	NaN	2016	700 12TH AVE S	NASHVILLE	TN
56634	093 13 0D 056.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161031-0114730	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	320000	2016-10-26	No	NaN	2016	700 12TH AVE S	NASHVILLE	TN
56635	093 13 0D 094.00	700 12TH AVE S, NASHVILLE	RESIDENTIAL CONDO	NaN	20161104-0117077	NaN	NaN	NaN	NaN	NaN	...	NaN	NaN	330000	2016-10-27	No	NaN	2016	700 12TH AVE S	NASHVILLE	TN
30462 rows × 21 columns

ndf = ndf.drop(columns = ['ParcelID','PropertyAddress','OwnerName','LegalReference','Acreage','TaxDistrict',
                    'Bedrooms','FullBath','HalfBath','SaleDate','YearBuilt','Street','State'])
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
Cell In[89], line 1
----> 1 ndf = ndf.drop(columns = ['ParcelID','PropertyAddress','OwnerName','LegalReference','Acreage','TaxDistrict',
      2                     'Bedrooms','FullBath','HalfBath','SaleDate','YearBuilt','Street','State'])
      4 ndf

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\core\frame.py:5258, in DataFrame.drop(self, labels, axis, index, columns, level, inplace, errors)
   5110 def drop(
   5111     self,
   5112     labels: IndexLabel = None,
   (...)
   5119     errors: IgnoreRaise = "raise",
   5120 ) -> DataFrame | None:
   5121     """
   5122     Drop specified labels from rows or columns.
   5123 
   (...)
   5256             weight  1.0     0.8
   5257     """
-> 5258     return super().drop(
   5259         labels=labels,
   5260         axis=axis,
   5261         index=index,
   5262         columns=columns,
   5263         level=level,
   5264         inplace=inplace,
   5265         errors=errors,
   5266     )

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\core\generic.py:4549, in NDFrame.drop(self, labels, axis, index, columns, level, inplace, errors)
   4547 for axis, labels in axes.items():
   4548     if labels is not None:
-> 4549         obj = obj._drop_axis(labels, axis, level=level, errors=errors)
   4551 if inplace:
   4552     self._update_inplace(obj)

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\core\generic.py:4591, in NDFrame._drop_axis(self, labels, axis, level, errors, only_slice)
   4589         new_axis = axis.drop(labels, level=level, errors=errors)
   4590     else:
-> 4591         new_axis = axis.drop(labels, errors=errors)
   4592     indexer = axis.get_indexer(new_axis)
   4594 # Case for non-unique axis
   4595 else:

File C:\ProgramData\anaconda3\Lib\site-packages\pandas\core\indexes\base.py:6699, in Index.drop(self, labels, errors)
   6697 if mask.any():
   6698     if errors != "ignore":
-> 6699         raise KeyError(f"{list(labels[mask])} not found in axis")
   6700     indexer = indexer[~mask]
   6701 return self.delete(indexer)

KeyError: "['ParcelID', 'PropertyAddress', 'OwnerName', 'LegalReference', 'Acreage', 'TaxDistrict', 'Bedrooms', 'FullBath', 'HalfBath', 'SaleDate', 'YearBuilt', 'Street', 'State'] not found in axis"

ndf
ndf
LandUse	Land_Value($)	Building_Value($)	Total_Value($)	Sale_Price($)	SoldAsVacant	SaleYear	County
UniqueID								
0	RESIDENTIAL CONDO	NaN	NaN	NaN	132000	No	2013	NASHVILLE
6	RESIDENTIAL CONDO	NaN	NaN	NaN	64900	No	2013	NASHVILLE
17	RESIDENTIAL CONDO	NaN	NaN	NaN	31416	No	2013	NASHVILLE
18	RESIDENTIAL CONDO	NaN	NaN	NaN	127500	No	2013	NASHVILLE
25	SINGLE FAMILY	NaN	NaN	NaN	270000	No	2013	BRENTWOOD
...	...	...	...	...	...	...	...	...
56631	RESIDENTIAL CONDO	NaN	NaN	NaN	210000	No	2016	NASHVILLE
56632	RESIDENTIAL CONDO	NaN	NaN	NaN	338000	No	2016	NASHVILLE
56633	RESIDENTIAL CONDO	NaN	NaN	NaN	742000	No	2016	NASHVILLE
56634	RESIDENTIAL CONDO	NaN	NaN	NaN	320000	No	2016	NASHVILLE
56635	RESIDENTIAL CONDO	NaN	NaN	NaN	330000	No	2016	NASHVILLE
30462 rows × 8 columns

fig, ax = plt.subplots(1, figsize = (20,8))
ax.grid()
fig.autofmt_xdate()
sns.countplot(data=ddf,x='LandUse')
plt.show()

ty
fig, ax = plt.subplots(1, figsize = (20,8))
ax.grid()
fig.autofmt_xdate()
sns.countplot(data=ddf,x='County')
plt.show()

#changing string values to numerical 
ndf['LandUse'] = ndf.groupby(ndf.LandUse.tolist(),sort=False).ngroup()
​
ndf['County'] = ndf.groupby(ndf.County.tolist(),sort=False).ngroup()
​
ndf['SoldAsVacant'] = ndf.groupby(ndf.SoldAsVacant.tolist(),sort=False).ngroup()
​
​
ndf.corr()
LandUse	Land_Value($)	Building_Value($)	Total_Value($)	Sale_Price($)	SoldAsVacant	SaleYear	County
LandUse	1.00	NaN	NaN	NaN	0.00	0.71	0.08	0.09
Land_Value($)	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN
Building_Value($)	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN
Total_Value($)	NaN	NaN	NaN	NaN	NaN	NaN	NaN	NaN
Sale_Price($)	0.00	NaN	NaN	NaN	1.00	-0.01	0.02	-0.06
SoldAsVacant	0.71	NaN	NaN	NaN	-0.01	1.00	-0.03	0.09
SaleYear	0.08	NaN	NaN	NaN	0.02	-0.03	1.00	0.03
County	0.09	NaN	NaN	NaN	-0.06	0.09	0.03	1.00
Looking at the Null DataFrame, we can see there is no obvious connection between Sale and any of the other columns, however there is a connection between landuse and soldasvacant.
MACHINE LEARNING EXERCISE 
For this Exercise, we will be using Detailed DataFrame (ddf) as our base for the train, test and split model. In this data, we will focus on creating 2 targets.
First target will be Total_value, and we will use Building values, Bedroom, Fullbath and land_values (using Linear regressor and K Neighbor Regressor)

Second target will be Sale_Price($), and we will be using Building values, FullBath, Bedroom Total_value and land_values (using DT regressor and Random ForestRegressor)

t
from sklearn.model_selection import train_test_split , GridSearchCV, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, f1_score, r2_score
​
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
ddf = ddf.dropna()
​
#ddf=ddf.drop(columns = ['ParcelID','PropertyAddress','OwnerName','LegalReference','SaleDate','Street','State','TaxDistrict','SoldAsVacant',
                  # 'LandUse','County'])
​
​
X = ddf.drop('Total_Value($)',axis = 1)
y = ddf['Total_Value($)']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4) #check random state
X = ddf.drop('Total_Value($)',axis = 1)
y = ddf['Total_Value($)']
​
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4) #check random state
row, col = X_train.shape
print("X_train have",row,"rows and",col,"columns.")
row, col = X_test.shape
print("X_test have",row,"rows and",col,"columns.")
row, col = X_train.shape
print("X_train have",row,"rows and",col,"columns.")
row, col = X_test.shape
print("X_test have",row,"rows and",col,"columns.")
X_train have 14407 rows and 9 columns.
X_test have 9606 rows and 9 columns.
model = LinearRegression()

test_sizes = [0.15, 0.2, 0.25, 0.3, 0.4]
random_states = [0, 1, 42, 58, 100, 412]

best_test_size = None
best_random_state = None
best_r2_score = -float('inf')

for test_size in test_sizes:
    for random_state in random_states:
        X_train, X_test, y_train, y_test = train_test_split(ddf.drop('Total_Value($)', axis=1), ddf['Total_Value($)'], test_size=test_size, random_state=random_state)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        if r2 > best_r2_score:
            best_r2_score = r2
            best_test_size = test_size
            best_random_state = random_state

print(f"Best test size: {best_test_size}")
print(f"Best random state: {best_random_state}")
print(f"Best R2 score: {best_r2_score}")
model = LinearRegression()
​
test_sizes = [0.15, 0.2, 0.25, 0.3, 0.4]
random_states = [0, 1, 42, 58, 100, 412]
​
best_test_size = None
best_random_state = None
best_r2_score = -float('inf')
​
for test_size in test_sizes:
    for random_state in random_states:
        X_train, X_test, y_train, y_test = train_test_split(ddf.drop('Total_Value($)', axis=1), ddf['Total_Value($)'], test_size=test_size, random_state=random_state)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        if r2 > best_r2_score:
            best_r2_score = r2
            best_test_size = test_size
            best_random_state = random_state
​
print(f"Best test size: {best_test_size}")
print(f"Best random state: {best_random_state}")
print(f"Best R2 score: {best_r2_score}")
Best test size: 0.2
Best random state: 42
Best R2 score: 0.9994501267777139
X_train, X_test , y_train, y_test = train_test_split(ddf.drop('Total_Value($)', axis=1), ddf['Total_Value($)'], test_size=.2, random_state=43)

LRmodel = LinearRegression(fit_intercept=True)
LRmodel.fit(X_train, y_train)
X_train, X_test , y_train, y_test = train_test_split(ddf.drop('Total_Value($)', axis=1), ddf['Total_Value($)'], test_size=.2, random_state=43)
​
LRmodel = LinearRegression(fit_intercept=True)
LRmodel.fit(X_train, y_train)

LinearRegression
LinearRegression()
y_pred = LRmodel.predict(X_test)
r2_score(y_test, y_pred)
y_pred = LRmodel.predict(X_test)
r2_score(y_test, y_pred)
0.9994096029929725
<h2> K NEIGHBORS REGRESSOR </h2>
<h2> K NEIGHBORS REGRESSOR </h2>
model = KNeighborsRegressor()

test_sizes = [0.15, 0.2, 0.25, 0.3, 0.4]
random_states = [0, 1, 42, 58, 100, 313]

best_test_size = None
best_random_state = None
best_r2_score = -float('inf')

for test_size in test_sizes:
    for random_state in random_states:
        X_train, X_test, y_train, y_test = train_test_split(ddf.drop('Total_Value($)', axis=1), ddf['Total_Value($)'], test_size=test_size, random_state=random_state)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        if r2 > best_r2_score:
            best_r2_score = r2
            best_test_size = test_size
            best_random_state = random_state

print(f"Best test size: {best_test_size}")
print(f"Best random state: {best_random_state}")
print(f"Best R2 score: {best_r2_score}")
model = KNeighborsRegressor()
​
test_sizes = [0.15, 0.2, 0.25, 0.3, 0.4]
random_states = [0, 1, 42, 58, 100, 313]
​
best_test_size = None
best_random_state = None
best_r2_score = -float('inf')
​
for test_size in test_sizes:
    for random_state in random_states:
        X_train, X_test, y_train, y_test = train_test_split(ddf.drop('Total_Value($)', axis=1), ddf['Total_Value($)'], test_size=test_size, random_state=random_state)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        if r2 > best_r2_score:
            best_r2_score = r2
            best_test_size = test_size
            best_random_state = random_state
​
print(f"Best test size: {best_test_size}")
print(f"Best random state: {best_random_state}")
print(f"Best R2 score: {best_r2_score}")
Best test size: 0.2
Best random state: 313
Best R2 score: 0.9957578842926421
X_train, X_test, y_train, y_test = train_test_split(ddf.drop('Total_Value($)', axis=1), ddf['Total_Value($)'], test_size=0.2, random_state=0)

KNNmodel = KNeighborsRegressor()

param_grid = {
    'n_neighbors': range(3,11,2),
    'weights': ['uniform', 'distance'],
    'p': [1, 2]
}

grid_search = GridSearchCV(estimator=KNNmodel, param_grid=param_grid, scoring='r2', cv=5)
grid_search.fit(X_train, y_train)

best_r2_score = grid_search.best_score_
best_params = grid_search.best_params_
print(f"Best R2 score: {best_r2_score}")
print(f"Best hyperparameters: {best_params}")

best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
test_r2 = r2_score(y_test, y_pred)
print(f"R2 score on test set: {test_r2}")
X_train, X_test, y_train, y_test = train_test_split(ddf.drop('Total_Value($)', axis=1), ddf['Total_Value($)'], test_size=0.2, random_state=0)
​
KNNmodel = KNeighborsRegressor()
​
param_grid = {
    'n_neighbors': range(3,11,2),
    'weights': ['uniform', 'distance'],
    'p': [1, 2]
}
​
grid_search = GridSearchCV(estimator=KNNmodel, param_grid=param_grid, scoring='r2', cv=5)
grid_search.fit(X_train, y_train)
​
best_r2_score = grid_search.best_score_
best_params = grid_search.best_params_
print(f"Best R2 score: {best_r2_score}")
print(f"Best hyperparameters: {best_params}")
​
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
test_r2 = r2_score(y_test, y_pred)
print(f"R2 score on test set: {test_r2}")
Best R2 score: 0.986319225665186
Best hyperparameters: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}
R2 score on test set: 0.9956270922892014
